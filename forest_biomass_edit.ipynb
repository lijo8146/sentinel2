{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519eb7c-b617-4a39-b45f-d525e55da8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code was written by: Author: Ewelina Dobrowolska - ewelina.dobrowolska@serco.com\n",
    "# lightly edited by Lilly Jones to evaluate for SCE project\n",
    "\n",
    "#MODULE NAME                                             #DESCRIPTION\n",
    "import os                                                #data access to file manager \n",
    "import matplotlib as mpl                                 #create visualizations\n",
    "import matplotlib.colors as colors                       #create visualizations\n",
    "import matplotlib.image as mpimg                         #create visualizations\n",
    "import matplotlib.pyplot as plt                          #create visualizations\n",
    "import matplotlib.cm as cm                               #create visualizations\n",
    "import skimage.exposure as exposure                      #collection of algorithms for image processing\n",
    "import pandas as pd                                      #data analysis and manipulation\n",
    "import numpy as np                                       #scientific computing\n",
    "import subprocess                                        #allows you to spawn new processes\n",
    "import snappy                                            #SNAP Python interface\n",
    "import jpy                                               #Python-Java bridge\n",
    "import imageio                                           #visualize and process images \n",
    "import rasterio as rio                                   #working with geospatial raster data\n",
    "import rioxarray as rxr                                  #geospatial xarray extension employed in rasterio\n",
    "import rasterstats as rs                                 #summarizing geospatial raster datasets based on vector geometries\n",
    "import gdal                                              #Geospatial Data Abstraction Library for manipulating vecotr and raster data\n",
    "import rasterio.plot                                     #imagrs visualization with rasterio \n",
    "from glob import iglob                                   #data access in file manager\n",
    "from snappy import ProductIO                             #reading product in SNAP-Python interface\n",
    "from snappy import GPF                                   #allows to create products in SNAP-Python\n",
    "from snappy import Product                               #reading product in SNAP-Python interface\n",
    "from snappy import ProductData                           #access to product data in SNAP-Python\n",
    "from snappy import ProductUtils                          #access specific functions of snappy\n",
    "from snappy import FlagCoding                            #writing data to the band flag coding\n",
    "from snappy import WKTReader                             #reading the geometry from WKT coordinates\n",
    "from zipfile import ZipFile                              #allows to read .zip files       \n",
    "from osgeo import gdal, gdal_array, ogr                  #import major modules from gdal library \n",
    "import geopandas as gpd                                  #extention of databases used in pandas to allow spatial operations \n",
    "from pyspatialml import Raster                           #applying scikit-learn machine learning models to 'stacks' of raster datasets\n",
    "import seaborn as sns                                    #data visualization library based on matplotlib\n",
    "from rasterio.plot import show                           #visualization of images using rasterio plot  \n",
    "from pathlib import Path                                 #read raster product path \n",
    "%matplotlib inline          \n",
    "\n",
    "#Change module setting - the maximum width of column in dataframe displayed\n",
    "pd.options.display.max_colwidth = 80                     #longer text in pd data frame (df)\n",
    "print('All modules loaded')                              #inform user once packages are loaded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae4256-75f0-481b-82c0-bc7acb20a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load aux data\n",
    "#Directory containing downloaded Sentinel 2 image (unzipped file)\n",
    "input_directory = '/shared/Training/PY02_ForestBiomass_Sentinel2/Original/'\n",
    "#Directory where all output products will be saved \n",
    "output_directory = '/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/'\n",
    "#Path to the input product (unzipped because of the atmospheric correction which requires data in .xml format)\n",
    "SL1C_product_path = input_directory + 'S2A_MSIL1C_20170119T074231_N0204_R092_T37NEH_20170119T075734.SAFE/MTD_MSIL1C.xml'\n",
    "#path to the training data points previously created\n",
    "points_path = '/shared/Training/PY02_ForestBiomass_Sentinel2/AuxData/points_agb_2017.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d919b1a-044a-4a40-99b5-e35928e44e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create band composites using snappy-Python environment \n",
    "#bands_com - are the bands which will be used for the creation of bands composites\n",
    "#filename - the path to the file with its name where the output will be stored\n",
    "# format_im - image format used to stored the results \n",
    "def write_band_composites(bands_com, filename, format_im):\n",
    "    image_info = ProductUtils.createImageInfo(bands_com, True, ProgressMonitor.NULL)\n",
    "    im = ImageManager.getInstance().createColoredBandImage(bands_com, image_info, 0)\n",
    "    JAI.create(\"filestore\", im, filename, format_im)\n",
    "\n",
    "#Function to calculate vegetation indices from band combinations\n",
    "#raster_output_name - name of the vegetation index which will be saved\n",
    "# VI_name - name of the vegetation index \n",
    "# cmap_output_name - name of the png file where the file will be stored with the colormap applied \n",
    "#plot_title - tile of the image produced \n",
    "def create_vegetation_indices(raster_output_name, VI_name, cmap_output_name, plot_title):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    kwargs = src.meta\n",
    "    kwargs.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count = 1)\n",
    "    #create the Vegetation Index geotiff file with the colormap \n",
    "    with rasterio.open(VI_output + raster_output_name, 'w', **kwargs) as dst:\n",
    "                        dst.write_band(1, VI_name.astype(rasterio.float32))\n",
    "    plt.imsave(VI_output+cmap_output_name, VI_name, cmap=plt.cm.RdYlGn)\n",
    "    plt.imshow(VI_name, cmap = cm.RdYlGn) \n",
    "    plt.colorbar() \n",
    "    plt.title(plot_title) \n",
    "    plt.show()\n",
    "#Normalizes numpy arrays into scale -1.0 - 1.0\n",
    "#array - indicates in this case the array of the image to normalize \n",
    "def normalize(array): \n",
    "    array_min, array_max = array.min(-1), array.max(1)\n",
    "    return ((array - array_min)/(array_max - array_min))\n",
    "#Extract vegetation indices values based on the polygons buffers (zones) previously created \n",
    "#VI_data - indicate the vegetation index transformed into array \n",
    "#poly_buffer_path - path to the file with the 20 m buffer stored in the local folder \n",
    "#VI_mean - vegetation index mean extracted from the polygons \n",
    "def zonal_statistics(VI_data):\n",
    "    VI_mean = rs.zonal_stats(poly_buffer_path,\n",
    "                             VI_data.values,\n",
    "                             nodata=-999,\n",
    "                             affine=VI_data.rio.transform(),\n",
    "                             geojson_out=True,\n",
    "                             copy_properties=True,\n",
    "                             stats=\"mean\")\n",
    "    return VI_mean\n",
    "#create geodataframe with the vegetation indices values \n",
    "#VI_mean - vegetation index mean value extracted to place int the geodataframe\n",
    "#VI_gdf - geodataframe with the vegetation index values \n",
    "def create_GeoDataFrame(VI_mean):\n",
    "    VI_gdf = gpd.GeoDataFrame.from_features(VI_mean)\n",
    "    return VI_gdf\n",
    "#create dataframe with the vegetation indcices without geo information \n",
    "#VI_df - dataframe which will be created with the vegetation index for each index\n",
    "def create_DataFrame(VI_gdf):\n",
    "    VI_df = pd.DataFrame(VI_gdf.drop(columns='geometry'))\n",
    "    VI_df = VI_df.drop(columns=['OID_', 'POINT_X', 'POINT_Y'])\n",
    "    return VI_df\n",
    "# Create a GeoTIFF file with the given data (in this case this will be used in the step where we prepare new raster with predicted biomass values\n",
    "#outRaster -indicates the output raster created\n",
    "#data - predictor variables (vegetation indices - which will predict the AGB values)\n",
    "#to create the raster gdal library will be used \n",
    "#projection - projection of the raster set \n",
    "def createGeotiff(outRaster, data, geo_transform, projection):\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    rows, cols = data.shape\n",
    "    rasterDS = driver.Create(outRaster, cols, rows, 1, gdal.GDT_Float32)\n",
    "    rasterDS.SetGeoTransform(geo_transform)\n",
    "    rasterDS.SetProjection(projection)\n",
    "    band = rasterDS.GetRasterBand(1)\n",
    "    band.WriteArray(data)\n",
    "    rasterDS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22106b7a-3515-49ad-8702-34292418a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following requires the Sen2cor toolbox\n",
    "\n",
    "#Read input Sentinel 2 L1C image to snappy \n",
    "sentinel_L1C = snappy.ProductIO.readProduct(SL1C_product_path)\n",
    "#Atmospheric correction from 1c to 2A level using Sen2Cor toolbox version 280\n",
    "parameters = snappy.HashMap() #setting parameters for processing the image \n",
    "parameters.put('resolution', 'ALL')  #final product will have all three resolutions: 10, 20 and 60m\n",
    "s2A = snappy.GPF.createProduct('Sen2Cor280', parameters, sentinel_L1C) #run processing and save the product\n",
    "print('Done.') #once processing is finished user will be informed about the end of processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b8713-e5f0-4ac8-8e19-886feb19cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling, band subset, band composition\n",
    "\n",
    "#Declare the path to the pre-processed S2A image\n",
    "s2A_path = input_directory + 'S2A_MSIL2A_20170119T074231_N9999_R092_T37NEH_20210805T145407.SAFE/MTD_MSIL2A.xml'\n",
    "s2A_read = ProductIO.readProduct(s2A_path) #read product using snappy \n",
    "name_original = s2A_read.getName() #substract the name of the product to write in the output name \n",
    "#Set parameters for resampling:\n",
    "parameters = snappy.HashMap()\n",
    "parameters.put('targetResolution', 20) #reference band resolution 20 m \n",
    "resample = snappy.GPF.createProduct('Resample', parameters, s2A_read) #perform resampling of the image bands\n",
    "#Show comunication when the processing is finished\n",
    "print('Resampled')\n",
    "#Set parameters for subset of the resampled product\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')\n",
    "parameters = HashMap()\n",
    "parameters.put('copyMetadata', True)\n",
    "parameters.put('sourceBands', 'B2,B3,B4,B5,B6,B8,B11,B12') #selection of bands to store in the final output product (subset)\n",
    "parameters.put('region','0,0,5490,5490') #set height and weight of the raster band for all the bands \n",
    "subset = snappy.GPF.createProduct('Subset', parameters, resample) #perform subset using as input file resampled product\n",
    "print('Subset created') #comunicate when the subset is being created \n",
    "subset_path = output_directory + 'S2/' #path where the subset product will be stored\n",
    "ProductIO.writeProduct(subset,subset_path + name_original + '_subset.dim', 'BEAM-DIMAP') #saving subset as .dim format\n",
    "print('Product written')\n",
    "ProductIO.writeProduct(subset,subset_path +name_original + '_subset.tif', 'GeoTIFF')     #saving subset as .tiff format\n",
    "print('GeoTIFF product written')\n",
    "\n",
    "#Indicate the path to atmospherically corrected Sentinel-2A image: \n",
    "product_path = output_directory + 'S2/S2A_MSIL2A_20170119T074231_N9999_R092_T37NEH_20210805T145407_subset.tif'\n",
    "subset_product = ProductIO.readProduct(product_path) #read image in snappy module \n",
    "#first we need to import all the bands and give them the shorter name to display and to read properly in snappy module \n",
    "B2 = subset_product.getBand('B2')    #blue band\n",
    "B3 = subset_product.getBand('B3')    #green band\n",
    "B4 = subset_product.getBand('B4')    #red band (visible spectrum)\n",
    "B8 = subset_product.getBand('B8')    #NIR\n",
    "B11 = subset_product.getBand('B11')  #SWIR1\n",
    "B12 = subset_product.getBand('B12')  #SWIR2\n",
    "\n",
    "#Using snappy to create band compositions (import necessary modules)\n",
    "from snappy import (ProductIO, ProductUtils, ProgressMonitor)\n",
    "path_band_composites = '/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/RGB/' #path to output product \n",
    "image_format = 'PNG' #band composites will be saved to .png image format \n",
    "# Java type definitions required for image generation in snappy\n",
    "jpy_s = snappy.jpy                      \n",
    "Color = jpy_s.get_type('java.awt.Color')\n",
    "ColorPoint = jpy_s.get_type('org.esa.snap.core.datamodel.ColorPaletteDef$Point')  \n",
    "ColorPaletteDef = jpy_s.get_type('org.esa.snap.core.datamodel.ColorPaletteDef')  \n",
    "ImageInfo = jpy_s.get_type('org.esa.snap.core.datamodel.ImageInfo')            \n",
    "ImageLegend = jpy_s.get_type('org.esa.snap.core.datamodel.ImageLegend')          \n",
    "ImageManager = jpy_s.get_type('org.esa.snap.core.image.ImageManager')          \n",
    "JAI = jpy_s.get_type('javax.media.jai.JAI')                                    \n",
    "RenderedImage = jpy_s.get_type('java.awt.image.RenderedImage')\n",
    "# Disable JAI native MediaLib extensions - print true if the extensons are ready\n",
    "System = jpy_s.get_type('java.lang.System')\n",
    "System.setProperty('com.sun.media.jai.disableMediaLib', 'true')\n",
    "\n",
    "#Create band composites using pre-defined funcnction from section 3 \n",
    "write_band_composites ([B4, B3, B2], path_band_composites + 'RGB_20170119.png', image_format) #RGB band composites - Natural color \n",
    "write_band_composites ([B8, B4, B3], path_band_composites + 'fColor_20170119.png', image_format) # False-color band composite \n",
    "write_band_composites ([B8, B11, B2], path_band_composites + 'vegfColor_20170119.png', image_format) #False color band composite 2 \n",
    "print('Band composites written') #inform user when the band composites are saved in output folder \n",
    "\n",
    "# Create Gif from the list of .png files\n",
    "from pathlib import Path\n",
    "image_path = Path(path_band_composites) #path to folder with band composites \n",
    "images = list(image_path.glob('*.png')) #list all products using glob module with the extension .png\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "#Create GIF from the list of band composites \n",
    "gif = imageio.mimwrite('/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/RGB/'+'RGB_composite.gif', image_list, fps=2)\n",
    "print('RGB bands composites saved as Giff')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec238cf-3145-46c0-a93b-a47c8d7d7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vegetation indices\n",
    "\n",
    "print(list(subset_product.getBandNames())) #print names of bands\n",
    "\n",
    "# Load Sentinel 2 bands needed for calculation of Vegetation indices and masking no data values in case there are some before the calculations\n",
    "with rasterio.open(product_path) as src:\n",
    "    band_4 = src.read(3, masked=True) #red band\n",
    "    band_5= src.read(4, masked=True) #VRed-Edge band   \n",
    "    band_8= src.read(6, masked=True) #NIR band\n",
    "    band_11= src.read(7, masked=True) #SWIR1 band\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "#set output path to the folder where the Vegetation indices will be stored \n",
    "VI_output = '/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/VI_output/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93960c16-5c6e-46a3-9797-f4a08a0ad6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NDVI\n",
    "\n",
    "#Equation to calculate NDVI index\n",
    "ndvi = (band_8.astype(float) - band_4.astype(float)) / (band_8 + band_4)\n",
    "#create NDVI bands with the use of \"create_vegetation_indices function from section 3 - User-defined functions\"\n",
    "#the results will be written into tif and png file with the colormap applied\n",
    "ndvi_results = create_vegetation_indices('1_NDVI.tif', ndvi, '1_NDVI_cmap.png', 'NDVI_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90647aa-6477-422b-98a8-abcd5f9e483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized difference index\n",
    "\n",
    "# Calculate NDI45 using formula above\n",
    "ndi45 = (band_5.astype(float) - band_4.astype(float)) / (band_5 + band_4)\n",
    "#create NDI45 band with the use of \"create_vegetation_indices function from section 3 - User-defined functions\"\n",
    "ndi45_results = create_vegetation_indices('2_NDI45.tif', ndi45, '2_NDI45_cmap.png', 'NDI45_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f627a96-9d8c-403a-941e-e36cd98c85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soil adjusted vegetation index\n",
    "\n",
    "#Calculate SAVI using formula above\n",
    "l = 0.428 # L parameter assigned\n",
    "savi = (band_8.astype(float) - band_4.astype(float)) / (band_8 + band_4 + l) * (1+l)\n",
    "#normalize raster results to the scale: -1 tp 1:\n",
    "savi_n = normalize(savi)\n",
    "#create SAVI band with the use of \"create_vegetation_indices function from section 3 - User-defined functions\"\n",
    "savi_results = create_vegetation_indices('3_SAVI.tif', savi_n, '3_SAVI_cmap.png', 'SAVI_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729070b6-cf56-4a41-a067-72b765a39061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized difference moisture index\n",
    "\n",
    "#Calculate NDMI using formula above\n",
    "ndmi = (band_8.astype(float) - band_11.astype(float)) / (band_8 +  band_11 ) \n",
    "#create NDMI band with the use of \"create_vegetation_indices function from section 3 - User-defined functions\"\n",
    "ndmi_results = create_vegetation_indices('4_NDMI.tif', ndmi, '4_NDMI_cmap.png', 'NDMI_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924a860-aa10-46cb-9a94-4e6326f62911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster stack of veg indices\n",
    "\n",
    "#import list of files (rasters) to create image stack \n",
    "from glob import glob\n",
    "glist = sorted(glob(\"/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/VI_output/*.tif\")) \n",
    "#import list of products with the extension .tif \n",
    "glist #print list of products which will be included in raster stack\n",
    "\n",
    "#read all metadata of all single raster bands: \n",
    "with rasterio.open(glist[0]) as src0:\n",
    "    meta = src0.meta\n",
    "meta.update(count = len(glist))\n",
    "#rad each single band of vegetation indices and load them to rasterio module\n",
    "with rasterio.open('/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/VIs_stack.tif', 'w', **meta) as dst:\n",
    "    for id, layer in enumerate(glist, start=1):\n",
    "        with rasterio.open(layer) as src1:\n",
    "            dst.write_band(id, src1.read(1))\n",
    "#save raster stack in the output folder\n",
    "with rio.open('/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/VIs_stack.tif') as stack_src:\n",
    "    stack_data = stack_src.read(masked=True)\n",
    "    stack_meta = stack_src.profile\n",
    "stack_meta #display metadata of the produt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd3e0c-81b1-4ca9-8298-6cd4fedde7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training points shapefile\n",
    "\n",
    "#READ SHAPEFILE INTO PYTHON ENVIRONMENT\n",
    "pts = gpd.read_file(points_path) #points will be read into Python using geopandas module \n",
    "print(pts.count()) #here we will display basic information about the points shapefile \n",
    "\n",
    "#IMPORT VEGETATION RASTER STACK USING RASTERIO PACKAGE \n",
    "VIs_stack = rasterio.open('/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/VIs_stack.tif') #set path to the raster stack \n",
    "fig, ax = plt.subplots(figsize=(10,10)) #set the size of the plot \n",
    "pts.plot(ax=ax, color = 'orangered') #plot imported points and set their color \n",
    "show(VIs_stack, ax=ax) #display the image (raster stack) together with points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccddc4-6151-4bbc-9577-ef70bbddb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create polygon shapefile with 20 m buffer\n",
    "\n",
    "#CREATE A BUFFER AROUND TRAINING POINTS  \n",
    "poly = pts.copy()  #make a copy of points shapefile previously loaded\n",
    "#Buffer each point using a 20 meter circle radius and replace the point geometry with the new buffered geometry \n",
    "poly[\"geometry\"] = pts.geometry.buffer(20) \n",
    "poly.head() \n",
    "# Export the buffered point layer as a shapefile to use in zonal stats \n",
    "poly_buffer_path = (\"poly_agb_buffer_20m.shp\") \n",
    "poly.to_file(poly_buffer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb79946-475c-4ebc-be8f-297f5e1dd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform zonal statistics\n",
    "#First we will open each file with vegetation index representation as an xarray and save it to VIs_data variable \n",
    "#Secondly we will calculate the mean of each VIs pixel value which fell inside the polygon created before. \n",
    "# We will save the results of statistics to new variable VIs_mean\n",
    "\n",
    "NDVI_data = rxr.open_rasterio(VI_output + '1_NDVI.tif', masked=True).squeeze()\n",
    "NDI45_data = rxr.open_rasterio(VI_output + '2_NDI45.tif', masked=True).squeeze()\n",
    "SAVI_data = rxr.open_rasterio(VI_output + '3_SAVI.tif', masked=True).squeeze()\n",
    "NDMI_data = rxr.open_rasterio(VI_output + '4_NDMI.tif', masked=True).squeeze()\n",
    "NDVI_mean = zonal_statistics(NDVI_data)\n",
    "NDI45_mean = zonal_statistics(NDI45_data)\n",
    "NDMI_mean = zonal_statistics(NDMI_data)\n",
    "SAVI_mean = zonal_statistics(SAVI_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa516e-4260-4c87-8ade-2a81b0dae003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create geodataframes and dataframes with the Vegetation Indices values. \n",
    "# Function to create dataframe is saved in the section 3 - User-defined functions\n",
    "\n",
    "gdf1 = create_GeoDataFrame(NDVI_mean)\n",
    "df1= create_DataFrame(gdf1)\n",
    "df1.rename(columns = {'_AGB_2017m': 'AGB_2017','mean':'NDVI'}, inplace = True)\n",
    "gdf2 = create_GeoDataFrame(NDI45_mean)\n",
    "df2= create_DataFrame(gdf2)\n",
    "df2.rename(columns = {'mean':'NDI45'}, inplace = True)\n",
    "gdf3 = create_GeoDataFrame(SAVI_mean)\n",
    "df3= create_DataFrame(gdf3)\n",
    "df3.rename(columns = {'mean':'SAVI'}, inplace = True)\n",
    "gdf4 = create_GeoDataFrame(NDMI_mean)\n",
    "df4= create_DataFrame(gdf4)\n",
    "df4.rename(columns = {'mean':'NDMI'}, inplace = True)\n",
    "\n",
    "#CREATE UNIQUE DATAFRAME WHICH CONTAINS ALL THE COLUMNS WITH VIS MEAN VALUES AT EACH POINT LOCATION \n",
    "training_dataset = pd.concat([df1,df2, df3, df4], axis=1, join='inner') #combine four dataframes previously created into unique database\n",
    "training_dataset = training_dataset.drop(columns=['ID', '_AGB_2017m']) #remove duplicated colums from the final databse (AGB_2017m and ID)\n",
    "\n",
    "# WRITE RECORDS OF THE TRAINING DATABASE TO .CSV FILE\n",
    "training_dataset.to_csv('training_dataset.csv', header =True, index=False)\n",
    "#display 6 first rows of the database created \n",
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a78fe8-216f-4b6e-9fea-545076caaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual representation of the correlation matrix using seaborn Python module\n",
    "corrMatrix = training_dataset.corr() #create first simple correlation matrix \n",
    "sns.heatmap(corrMatrix, annot=True) #plot the correlation matix as a heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1817a-edd2-4697-8039-ea254337795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear relationship between VIs and AGB values\n",
    "\n",
    "#Importing dataset using pandas package\n",
    "df = pd.read_csv('training_dataset.csv') \n",
    "\n",
    "#scatterplots between all four variables and the AGB values derived from the reference dataset \n",
    "#we will plot each vegetation index against the AGB values in order to see the relationship between these values and the \n",
    "#character of this relation. \n",
    "\n",
    "df.plot.scatter(x='NDVI', y='AGB_2017', s=60,c='green')\n",
    "df.plot.scatter(x='NDI45', y='AGB_2017', s=60,c='blue')\n",
    "df.plot.scatter(x='SAVI', y='AGB_2017', s=60,c='red')\n",
    "df.plot.scatter(x='NDMI', y='AGB_2017', s=60,c='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f36656-febc-4ecc-8eb1-163084388386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple linear regression model\n",
    "\n",
    "#CHOOSE COLUMNS WHICH INCLUDE ALL VARIABLES (X- PREDICTORS - VIs AND y - DEPENDENT VARIABLE) \n",
    "# WHICH WILL BE USED AS AN INPPUT TO ALL REGRESSION MODELS\n",
    "\n",
    "# use columns names from the dataframe created previously to select predictor variables for the model \n",
    "X = df.iloc[:, 1:5].values #as predictors we are going to use following values: \"NDVI_mean\", \"NDI45_mean\", \"SAVI_mean\" and \"NDMI_mean\"\n",
    "y = df.iloc[:, 0].values #dependent variable - AGB (tons/ha) is stored in the first column of the dataframe. \n",
    "\n",
    "#MULTIPLE LINEAR REGRESSION\n",
    "#import necessary classes to run multiple linear regression:\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model \n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm #display the results of statistics of the model \n",
    "#preparation of training and test dataset taking as an input training dataframe prepared previously, which contains all predictors and dependent variable values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) #30% of dataset will be left to test dataset in order to validate model\n",
    "from sklearn.linear_model import LinearRegression # Import linear regression class \n",
    "mlr_regressor = LinearRegression()   #perform multiple linear regression \n",
    "mlr_regressor.fit(x_train,y_train)   #fit training dataframe to the model prepared\n",
    "y_pred= mlr_regressor.predict(x_test) #predict new values of dependent variable (AGB values in our case), using test data remained\n",
    "#WRITE CALCULATION OF THE RESULTS TO SEPARATE DATAFRAME AND DISPLAY :\n",
    "mlr_results = {'Intercept':  [mlr_regressor.intercept_],\n",
    "        'Coefficients': [mlr_regressor.coef_],\n",
    "        'r-squared score': [mlr_regressor.score(x_train,y_train)]}\n",
    "mlr_df = pd.DataFrame (mlr_results, columns = ['Intercept','Coefficients','r-squared score'])\n",
    "mlr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690dcfa-84b5-4ba1-aa4a-bf91b9be9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "\n",
    "#Preapare training dataset for the model \n",
    "features = df.iloc[:, 1:5].values #predictor variables \n",
    "AGB_obs = df.iloc[:, 0].values #defined dependent variable\n",
    "from sklearn.model_selection import train_test_split \n",
    "#import class which enables to create the training and test data based on the input parameters \n",
    "train_features, test_features, train_AGB_obs, test_AGB_obs = train_test_split(features, AGB_obs, test_size = 0.3, random_state=0) \n",
    "#split training dataset into train and test data in the proportion that 30% of the dataset is saved for testing\n",
    "\n",
    "#RUN RANDOM FOREST REGRESSION MODEL\n",
    "from sklearn.ensemble import RandomForestRegressor #Import RandomForestRegressor class from sklearn module\n",
    "RFReg = RandomForestRegressor(n_estimators= 100, max_depth = 3, n_jobs=-1, random_state= 0) # create Random Forest model using 500 as a number of estimators\n",
    "RFReg.fit(train_features, train_AGB_obs) #fit the training dataset into the model \n",
    "\n",
    "#predict AGB values based on the created model with parameters pre-defined\n",
    "AGB_obs_pred_rf = RFReg.predict((test_features))\n",
    "from sklearn import metrics #assessing the results of estimation using R2 metric \n",
    "r_square_rf = metrics.r2_score(test_AGB_obs, AGB_obs_pred_rf)\n",
    "print('r-square:', r_square_rf) #dipslay r2 metric of the calculated model \n",
    "\n",
    "\n",
    "#here we will produce the numerical values of the importance of each VIs value to the final model \n",
    "rf_features = df.iloc[:, 1:5] #list of predictors used in the model \n",
    "features_list = list(rf_features.columns) # list the features used in the model\n",
    "importances = list(RFReg.feature_importances_) # importance of each predictor on the whole model \n",
    "#the values of the importance will be calculated based on the model \n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(features_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];#display results as a pair observations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e5576-fb69-42bf-a2ba-752316f7c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate above ground biomass based on linear regression model\n",
    "\n",
    "#Here we create the geotiff file which will contain predicted AGB values \n",
    "inpRaster= '/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/VIs_stack.tif' \n",
    "#define path to the input raster (on which we will make prediction\n",
    "df_train = pd.read_csv('training_dataset.csv') #path to the dataset with the training data \n",
    "data = df_train[['NDVI','NDI45','SAVI','NDMI']] # list of predictors \n",
    "label = df_train['AGB_2017'] # predicted variable (dependent variable AGB)\n",
    "ds = gdal.Open(inpRaster, gdal.GA_ReadOnly) #with gdal module we will open the input raster \n",
    "rows = ds.RasterYSize #we need to asisgn the size of the raster - rows number in the raster dataset \n",
    "cols = ds.RasterXSize # we need to asisgn the size of the raster - columns number in the raster dataset \n",
    "bands = ds.RasterCount #we will also get the number of bands in the input raster (in our case 4)\n",
    "geo_transform = ds.GetGeoTransform() #with geotransform class we will set projection to the raster \n",
    "projection = ds.GetProjectionRef() #projection of the raster needs to be the same as input raster \n",
    "array = ds.ReadAsArray() #raster will be converted to an array\n",
    "ds = None\n",
    "array = np.stack(array,axis=2) #with numpy stack we will join the sequence of the arrays along a new axes  \n",
    "array = np.reshape(array, [rows*cols,bands]) \n",
    "#we give a final shape to the output raster: number of columns and rows and bands must be the same as input file \n",
    "test = pd.DataFrame(array, dtype='float32')  # we will create raster with the same datatype 'float32' as input raster \n",
    "outRaster = '/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/AGB_mlr.tif' #path to the output raster - where it will be saved\n",
    "#PREDICTION OF ABOVEGROUND BIOMASS VALUES BASED ON THE TRAINING DATASET AND THE RASTER STACK PROVIDED \n",
    "AGB_mlr = mlr_regressor.predict(test) #run the prediction on multiple linear regression model previously created \n",
    "estimation = AGB_mlr.reshape((rows,cols)) #reshape output array into the array with the same defined previously number of columns and rows. \n",
    "\n",
    "#export classified image using 'createGeotiff' function provided in the section number 3\n",
    "createGeotiff(outRaster,estimation,geo_transform,projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0489ae5-8a4c-4cca-a4ea-439f49830428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agb based on random forest regression model \n",
    "\n",
    "#Here we will run script which is very similar to the cell above, this time taking as a predictor of values Random Forest Regression model \n",
    "inpRaster= '/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/VIs_stack.tif' \n",
    "#define path to the input raster (on which we will make prediction\n",
    "outRaster = '/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/AGB_RFReg.tif' #path to the output raster - where it will be saved\n",
    "df_train = pd.read_csv('training_dataset.csv') #path to the dataset with the training data \n",
    "data = df_train[['NDVI','NDI45','SAVI','NDMI']] # list of predictors \n",
    "label = df_train['AGB_2017']  # predicted variable (dependent variable AGB)\n",
    "ds = gdal.Open(inpRaster, gdal.GA_ReadOnly) #with gdal module we will open the input raster \n",
    "rows = ds.RasterYSize #we need to asisgn the size of the raster - rows number in the raster dataset \n",
    "cols = ds.RasterXSize # we need to asisgn the size of the raster - columns number in the raster dataset \n",
    "bands = ds.RasterCount  #we will also get the number of bands in the input raster (in our case 4)\n",
    "geo_transform = ds.GetGeoTransform() #with geotransform class we will set projection to the raster \n",
    "projection = ds.GetProjectionRef()  #projection of the raster needs to be the same as input raster \n",
    "array = ds.ReadAsArray() #raster will be converted to an array\n",
    "ds = None\n",
    "array = np.stack(array,axis=2)  #with numpy stack we will join the sequence of the arrays along a new axes \n",
    "array = np.reshape(array, [rows*cols,bands])  \n",
    "#we give a final shape to the output raster: number of columns and rows and bands must be the same as input file \n",
    "test1 = pd.DataFrame(array, dtype='float32') # we will create raster with the same datatype 'float32' as input raster \n",
    "#PREDICTION OF ABOVEGROUND BIOMASS VALUES BASED ON THE TRAINING DATASET AND THE RASTER STACK PROVIDED \n",
    "AGB_RFReg = RFReg.predict(test1) #run the prediction on Random Forest Regression model previously created \n",
    "estimation = AGB_RFReg.reshape((rows,cols)) #reshape output array into the array with the same defined previously number of columns and rows\n",
    "##export classified image using 'createGeotiff' function provided in the section number 3\n",
    "createGeotiff(outRaster,estimation,geo_transform,projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edcee2-03bb-4e6e-99af-b7447c4d279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations\n",
    "\n",
    "#read the output raster and open it\n",
    "AGB_mlr = rasterio.open('/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/AGB_mlr.tif')\n",
    "AGB_mlr_array = AGB_mlr.read() # Read all bands as an array\n",
    "# Calculate statistics for the image\n",
    "stats = []\n",
    "for band in AGB_mlr_array:\n",
    "    stats.append({\n",
    "    'min': band.min(),\n",
    "    'mean': band.mean(),\n",
    "    'median': np.median(band),\n",
    "    'max': band.max()})\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774e88e-7e8d-439e-a550-e7e027c52fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the output raster and open it\n",
    "AGB_RF = rasterio.open('/shared/Training/PY02_ForestBiomass_Sentinel2/Processing/AGB_RFReg.tif')\n",
    "AGB_RF_array = AGB_RF.read() # Read all bands as an array\n",
    "# Calculate statistics for the image\n",
    "stats = []\n",
    "for band in AGB_RF_array:\n",
    "    stats.append({\n",
    "    'min': band.min(),\n",
    "    'mean': band.mean(),\n",
    "    'median': np.median(band),\n",
    "    'max': band.max()})\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e54938-7815-4001-bed4-950bd2c0a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the reference data (AGB refernce map for the year 2017 and confront it with the results produced with the regression models \n",
    "AGB_ref = rasterio.open('/shared/Training/PY02_ForestBiomass_Sentinel2/AuxData/AGB_2017_resampled.tif')\n",
    "AGB_ref_array = AGB_ref.read() # Read all bands as an array\n",
    "fig, (ax1, ax2, ax3)= plt.subplots(1,3, figsize=(18,18)) #create a plot of three images one next to another  \n",
    "ax1.imshow(AGB_mlr_array[0], cmap= 'Greens', vmin = 0, vmax = 400)  #show the first image - AGB derived from the Multiple Linear Regression model\n",
    "ax1.set_title('AGB [tons/ha] - MLR model') \n",
    "ax2.imshow(AGB_RF_array[0], cmap= 'Greens',vmin = 0, vmax = 400) \n",
    "ax2.set_title('AGB [tons/ha] - RFR model') \n",
    "ax3.imshow(AGB_ref_array[0], cmap= 'Greens',vmin = 0, vmax = 400) \n",
    "ax3.set_title('AGB [tons/ha] - reference (BCCI)')\n",
    "for ax in fig.get_axes(): \n",
    "    ax.label_outer() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
